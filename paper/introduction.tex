\section{Introduction}

Working with big data sets has gained growing significance in the past years. This means processing heterogeneous gigabytes or terabytes of plain text by filtering, grouping or applying functions on the whole set or elements. One solution to this problem is using the Map/Reduce paradigm~\cite{googleMapReduce}~, which enables a cluster of computers to process a problem in parallel and thereby increase the processing speed.

Apache Hadoop is an Open Source Implementation of Map/Reduce~\cite{hadoopWebsite}~. It is published under the Apache License and maintained by the Apache Foundation. Its development is mostly driven by Yahoo! employees.

Hadoop programs are written in Java for the Hadoop API. On Hadoop, several domain specific languages try to establish a more abstract approach for utilizing the Map/Reduce paradigm. We have chosen to compare Pig and Jaql regarding their feature set, ease of programming and processing speed.

All source code written for the benchmarks in this paper are published online under Apache License. \footnote{available at http://github.com/rkh/hadoop-scripting/}