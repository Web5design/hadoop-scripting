\section{Programming With Pig}

For using Pig, two ways are possible. One is Grunt, an interactive Shell for Pig. The other way is evaluating an external script with Pig. Both ways work in localmode (PIG standalone) and in Hadoop Mode.
                              
A typical Pig Latin line of code looks like listing \ref{pigsample}.

\begin{lstlisting}[language=pig,caption=A typical Pig line of code,label=pigsample]
ordered = ORDER words;
\end{lstlisting}

This is the data transformation of one set (``words'') with an operation (``ORDER'') into a new set (``ordered''). The input data sets are always on the right side of the equation. The resulting output data set is always on the left side.

Most often Pig Latin Scripts naturally follow this listings structure \ref{pigstructure}.

\begin{lstlisting}[language=pig,caption=Pig Latin Script Structure ,label=pigstructure]
Load Data -> Manipulate Data -> Group Data -> Output Data
\end{lstlisting}
                                                       
A Pig Latin script is always started by a LOAD statement. The loaded is manipulated via FILTER, FOREACH ... GENERATE or DISTINCT statements or with the help of user-defined functions. Afterwards the Data gets grouped. Then the cycle either starts all over again e.g. with additional data being joined or the resulting data set is written to the output with a STORE statement. Of course this structure is not compulsory.
                   
Every dataset has a schema determining the structure of the data. These schemas may be defined explicitly by the user, implicitly by Pig or in a UDF. Certain attributes in a data set are to be accessed either via name in the schema or via position in the schema.

As already stated Pig has the same possibilities as native Java Hadoop due to the use of user-defined functions (UDF \ref{pigudf}).

There are three classes of UDFs:
 Eval Functions
 Aggregate Functions
 Filter Functions
 
The development of UDFs is well documented but requires noteworthy more effort than just writing Pig Latin. Especially defining own schemas can be a hard-to-debug task. 

Pig Latin scripts are best to debugged with the ILLUSTRATE, DESCRIBE and DUMP statements, which are giving access to the schema and the data of the data sets. Unfortunately Schemas are only to be determained one level deep and therefor deeper nested data structures are hard to debug.